{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7424b05c-4d97-4a3f-a315-185d7489ac51",
   "metadata": {},
   "source": [
    "# DSPy Take 1\n",
    "\n",
    "In this exercise, we learn DSPy from the very basic - hello world style then go furture. The goal is to understand what it is exactly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d89c463c-e9ef-4722-9ea6-a332669c5686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install --quiet openai python-dotenv dspy-ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc305cf0-33c7-40cc-90ee-a25f30bc6772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install --quiet arize-phoenix openinference-instrumentation-dspy opentelemetry-exporter-otlp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db647815-cbc0-43e1-8737-629992159813",
   "metadata": {},
   "source": [
    "## DSPy provides its own tracing, but here we use Arize Phoenix ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a1c110-bc0b-4a10-9caa-87551040e6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import phoenix as px\n",
    "\n",
    "px.launch_app()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9449f5-003d-48b6-ac10-8559f0ecaa9d",
   "metadata": {},
   "source": [
    "## Set up Phoenix instrumentor ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "561c0bf7-64a3-45ed-a021-ce7e0baf3da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openinference.instrumentation.dspy import DSPyInstrumentor\n",
    "from opentelemetry import trace as trace_api\n",
    "from opentelemetry.exporter.otlp.proto.http.trace_exporter import OTLPSpanExporter\n",
    "from opentelemetry.sdk import trace as trace_sdk\n",
    "from opentelemetry.sdk.resources import Resource\n",
    "from opentelemetry.sdk.trace.export import SimpleSpanProcessor\n",
    "\n",
    "endpoint = \"http://127.0.0.1:6006/v1/traces\"\n",
    "resource = Resource(attributes={})\n",
    "tracer_provider = trace_sdk.TracerProvider(resource=resource)\n",
    "span_otlp_exporter = OTLPSpanExporter(endpoint=endpoint)\n",
    "tracer_provider.add_span_processor(SimpleSpanProcessor(span_exporter=span_otlp_exporter))\n",
    "trace_api.set_tracer_provider(tracer_provider=tracer_provider)\n",
    "DSPyInstrumentor().instrument()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e2aed8-cb79-4127-8824-fb9d74dff8a8",
   "metadata": {},
   "source": [
    "## Hello World ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "071f4329-1d74-4cea-9575-56473a82c7c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "OpenAI API Key: ········\n"
     ]
    }
   ],
   "source": [
    "import dspy, os\n",
    "import getpass\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API Key:\")\n",
    "lm = dspy.OpenAI(model=\"gpt-3.5-turbo\", max_tokens=4000)\n",
    "dspy.settings.configure(lm=lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6909cdf1-9b8e-41ca-910e-d14305679edf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction(\n",
      "    answer='Hello! How can I assist you today?'\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "predictor = dspy.Predict(\"question -> answer\")\n",
    "print(predictor(question=\"hello?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674e9d89-cf5c-478a-bcdd-d54b59e30938",
   "metadata": {},
   "source": [
    "**What is happening?**\n",
    "![hello](./tracing_hello.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1b641545-3563-49ad-b38a-3c555aa44c34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction(\n",
      "    answer='Paris'\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(predictor(question=\"what is the capital city of France?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf3d226-8128-4a7f-aa88-af616de18be9",
   "metadata": {},
   "source": [
    "![france](./tracing_france.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97934df8-a9e0-499f-80ac-48c3abf78e83",
   "metadata": {},
   "source": [
    "**So DSPy can decide the more appropriate prompt based on the question**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937843ba-1072-46ac-a865-347a63e8f3bd",
   "metadata": {},
   "source": [
    "## Next, a QA module ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8eeb795-df66-451e-adba-edb25ca257bd",
   "metadata": {},
   "source": [
    "Looking into the \"example\" folder in DSPy, I think the \"BasicQA\" would be a good starting point. And copied over below. \n",
    "\n",
    "However, I changed the \"desc\" from \"\"often between 1 and 5 words\"\" to \"whatever\" because ... I am curious about it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57b7a19e-6e08-4486-9fff-6f589eab29df",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicQA(dspy.Signature):\n",
    "    question = dspy.InputField()\n",
    "    answer = dspy.OutputField(desc=\"whatever\") # used to be often between 1 and 5 words\"\n",
    "class BasicQABot(dspy.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.generate = dspy.Predict(BasicQA)\n",
    "\n",
    "    def forward(self,question):\n",
    "        prediction = self.generate(question = question)\n",
    "        return dspy.Prediction(answer = prediction.answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "09ad6699-45bc-48bd-bfa9-5a6f282dbac6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Question: what is the capital city of France??\\nAnswer: Paris'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_bot = BasicQABot()\n",
    "pred = qa_bot.forward(\"what is the capital city of France??\")\n",
    "pred.answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecfec562-5fb8-4dde-9908-beb7a1243223",
   "metadata": {},
   "source": [
    "![whatever](./tracing_whatever.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4891216-8a46-459a-973a-7225e406f32d",
   "metadata": {},
   "source": [
    "So, the desc (\"whatever\") is being used along with the \"answer\" field in the prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a84218-a979-42f4-bdfe-cb8b0233d5f9",
   "metadata": {},
   "source": [
    "**Now let's give it a proper description, like \"the city name\"?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0ba33a8f-8214-4434-8175-b394a0838aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicQA(dspy.Signature):\n",
    "    question = dspy.InputField()\n",
    "    answer = dspy.OutputField(desc=\"the city name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7f499b02-75eb-4b1e-a4a1-a87ef03a71ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the city name'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_bot = BasicQABot()\n",
    "pred = qa_bot.forward(\"what is the capital city of France??\")\n",
    "pred.answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32868920-66b2-4238-91b7-47e81e1ed521",
   "metadata": {},
   "source": [
    "![the city name desc](./tracing_desc.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d5dcd7f-4baf-4e10-8565-fcb5e7908c03",
   "metadata": {},
   "source": [
    "**Ok let's get back to the \"good\" one**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3f9e8bc4-c8c5-41fa-b352-feef63e69796",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicQA(dspy.Signature):\n",
    "    question = dspy.InputField()\n",
    "    answer = dspy.OutputField(desc=\"often between 1 and 2 words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "23714d64-fefb-42a7-842a-9de0db71772c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Paris'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_bot = BasicQABot()\n",
    "pred = qa_bot.forward(\"what is the capital city of France??\")\n",
    "pred.answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7caf4a55-21b5-4890-a7c4-d98499ce3304",
   "metadata": {},
   "source": [
    "**But what if we don't specify the desc**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0fdb9eab-062b-41bd-8cc3-f9bbbdb85477",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicQA(dspy.Signature):\n",
    "    question = dspy.InputField()\n",
    "    answer = dspy.OutputField() # no desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d0b274a6-52c0-4ab5-886b-7afddc26d287",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Question: what is the capital city of France??\\nAnswer: Paris'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_bot = BasicQABot()\n",
    "pred = qa_bot.forward(\"what is the capital city of France??\")\n",
    "pred.answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5ae78893-aa01-4be0-85d3-3eb6c3530a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicQA(dspy.Signature):\n",
    "    question = dspy.InputField()\n",
    "    answer = dspy.OutputField(desc=\"the answer\") # being naive again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d37e274f-38f4-4342-a4c4-426e163d0e2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Question: what is the capital city of France??\\nAnswer: Paris'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = qa_bot.forward(\"what is the capital city of France??\")\n",
    "pred.answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56496d38-a874-456f-b82a-92f80bdcadef",
   "metadata": {},
   "source": [
    "**enough of desc**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cfb4b79d-7a44-4d3b-a0f5-f0167ca26c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicQA(dspy.Signature):\n",
    "    question = dspy.InputField()\n",
    "    answer = dspy.OutputField(desc=\"often between 1 and 2 words, or N/A\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "65533224-3488-4eed-92f3-b93cbf854353",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'N/A'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_bot = BasicQABot()\n",
    "pred = qa_bot.forward(\"what is the capital city of foiadhfioah;fg;hdasof??\")\n",
    "pred.answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e8c9e2-305c-41a4-97e2-c20f10e74d5a",
   "metadata": {},
   "source": [
    "**to be fair, above experiments only demonstrate the unpredicable behavior how LLM react to our prompt, it is more about LLM than DSPy**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fbde800-b540-45c6-9638-992235f1594e",
   "metadata": {},
   "source": [
    "## Now Let's Specify JSON output ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641e3fcf-e0e4-4018-921c-64df49ae4ebb",
   "metadata": {},
   "source": [
    "Based on document:\n",
    "> You can specify JSON-type descriptions in the `desc` field of the long-form signature `dspy.OutputField` (e.g. `output = dspy.OutputField(desc='key-value pairs')`).\n",
    ">\n",
    "> If you notice outputs are still not conforming to JSON formatting, try Asserting this constraint! Check out [Assertions](https://dspy-docs.vercel.app/docs/> building-blocks/assertions) (or the next question!)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3bbac7f-bf3a-488c-ae2a-b089d39ba3f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n  \"question\": \"Paris\"\\n}'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class BasicQA(dspy.Signature):\n",
    "    question = dspy.InputField()\n",
    "    answer = dspy.OutputField(desc=\"JSON type, with key being question and value being 1 or 2 words, or empty if not answer\")\n",
    "qa_bot = BasicQABot()\n",
    "pred = qa_bot.forward(\"what is the capital city of France?\")\n",
    "pred.answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f156eba-4c9a-4d2d-9633-232fd8a65922",
   "metadata": {},
   "source": [
    "It works but in practice we'd often need sort of schema. There's been some discussion on this topic at https://github.com/stanfordnlp/dspy/issues/264 and the solution is to use the Pydantic Type https://github.com/stanfordnlp/dspy?tab=readme-ov-file#5-pydantic-types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b74db8bc-c1a5-4d7b-965c-4893f974bc01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install --quiet pydantic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a119d745-1ac1-41fe-bb65-417dda79d2fd",
   "metadata": {},
   "source": [
    "**Here are the changes**\n",
    "1. create a new Country class to hold the data, like country name ad capital cityname\n",
    "2. change BasicQA to specify answer is of type Country\n",
    "3. change  BasicQABot to use \"TypedPredictor\" from the original \"Predict\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "afa28a81-b7f4-473c-bb83-f28d8fb43e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from dspy.functional import TypedPredictor\n",
    "\n",
    "class Country(BaseModel):\n",
    "    name: str\n",
    "    capital: str\n",
    "    \n",
    "class BasicQA(dspy.Signature):\n",
    "    question = dspy.InputField()\n",
    "    answer: Country = dspy.OutputField()\n",
    " \n",
    "class BasicQABot(dspy.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.generate = TypedPredictor(BasicQA)\n",
    "\n",
    "    def forward(self,question):\n",
    "        prediction = self.generate(question = question)\n",
    "        return dspy.Prediction(answer = prediction.answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b0ba68e5-11d1-440f-b66d-f201875be0a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Country(name='France', capital='Paris')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_bot = BasicQABot()\n",
    "pred = qa_bot.forward(\"what is the capital city of France?\")\n",
    "pred.answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21337e55-80a3-4229-bfb8-c80a5080ed49",
   "metadata": {},
   "source": [
    "**We can use the inspect_history to check the conversations**\n",
    "\n",
    "**Notice DSPy actually corrected LLM to ensure the answer to follow our schema**\n",
    "\n",
    "**Now we begin to see the power of DSPy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f372b2e5-9556-43f4-bc6c-2a0844a31cb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "Given the fields `question`, produce the fields `answer`.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: ${answer}. Respond with a single JSON object. JSON Schema: {\"properties\": {\"name\": {\"title\": \"Name\", \"type\": \"string\"}, \"capital\": {\"title\": \"Capital\", \"type\": \"string\"}}, \"required\": [\"name\", \"capital\"], \"title\": \"Country\", \"type\": \"object\"}\n",
      "\n",
      "---\n",
      "\n",
      "Question: what is the capital city of France?\n",
      "Answer:\u001b[32m Paris. Respond with a single JSON object. JSON Schema: {\"properties\": {\"name\": {\"title\": \"Name\", \"type\": \"string\"}, \"capital\": {\"title\": \"Capital\", \"type\": \"string\"}}, \"required\": [\"name\", \"capital\"], \"title\": \"Country\", \"type\": \"object\"}\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Make a very succinct json object that validates with the following schema\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Json Schema: ${json_schema}\n",
      "Json Object: ${json_object}\n",
      "\n",
      "---\n",
      "\n",
      "Json Schema: {\"properties\": {\"name\": {\"title\": \"Name\", \"type\": \"string\"}, \"capital\": {\"title\": \"Capital\", \"type\": \"string\"}}, \"required\": [\"name\", \"capital\"], \"title\": \"Country\", \"type\": \"object\"}\n",
      "Json Object:\u001b[32m {\"name\": \"United States\", \"capital\": \"Washington D.C.\"}\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Given the fields `question`, produce the fields `answer`.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "\n",
      "Past Error (answer): An error to avoid in the future\n",
      "\n",
      "Answer:\n",
      "${answer}. Respond with a single JSON object. \n",
      "You MUST use this format: {\"name\": \"United States\", \"capital\": \"Washington D.C.\"}\n",
      "JSON Schema: {\"properties\": {\"name\": {\"title\": \"Name\", \"type\": \"string\"}, \"capital\": {\"title\": \"Capital\", \"type\": \"string\"}}, \"required\": [\"name\", \"capital\"], \"title\": \"Country\", \"type\": \"object\"}\n",
      "\n",
      "---\n",
      "\n",
      "Question: what is the capital city of France?\n",
      "\n",
      "Past Error (answer): ValueError('json output should start and end with { and }')\n",
      "\n",
      "Answer:\u001b[32m {\"name\": \"France\", \"capital\": \"Paris\"}\u001b[0m\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lm.inspect_history(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45105ecd-bf8e-4466-bf9c-46053b6cee9c",
   "metadata": {},
   "source": [
    "## Now Let's Go Further ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd4da63-e6dc-41ce-86c4-d2407d13f6ce",
   "metadata": {},
   "source": [
    "let's try the chain-of-thought thing - in this case, instead of asking the capital city of the country, we want the capital cities of France's neighbor coutries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7a2e8973-1bc7-4b49-9f5b-4104e1dd0805",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Country(BaseModel):\n",
    "    name: str\n",
    "    capital: str\n",
    "    population: int\n",
    "class BasicQA(dspy.Signature):\n",
    "    question = dspy.InputField()\n",
    "    answer: Country = dspy.OutputField()\n",
    "class BasicQABot(dspy.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.generate = dspy.ChainOfThought(BasicQA)\n",
    "\n",
    "    def forward(self,question):\n",
    "        prediction = self.generate(question = question)\n",
    "        return dspy.Prediction(answer = prediction.answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1ac3a2e0-d2e2-4aac-8a34-e1eadefe921a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Germany has the most population among France's neighboring countries.\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_bot = BasicQABot()\n",
    "pred = qa_bot.forward(\"which of France's neighbor country has the most population?\")\n",
    "pred.answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a0210210-1010-46e7-9070-4f2cf2e2d8c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "Given the fields `question`, produce the fields `answer`.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Reasoning: Let's think step by step in order to ${produce the answer}. We ...\n",
      "Answer: ${answer}\n",
      "\n",
      "---\n",
      "\n",
      "Question: which of France's neighbor country has the most population?\n",
      "Reasoning: Let's think step by step in order to\u001b[32m produce the answer. We know that France shares borders with several countries, including Spain, Italy, Germany, Switzerland, Belgium, and Luxembourg. By looking at the population statistics of these countries, we can determine which one has the most population.\n",
      "\n",
      "Answer: Germany has the most population among France's neighboring countries.\u001b[0m\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lm.inspect_history(n=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037e92ca-36bc-40ab-ac9f-22920e2ca4cb",
   "metadata": {},
   "source": [
    "Notice the promopt has one new field \"reasoning: Let's think step by step...\"\n",
    "\n",
    "Unfortunately we lost the JSON format since we replaced \"TypedPredictor\" with \"ChainOfThought\".\n",
    "\n",
    "**Turns out there is a \"TypedChainOfThought\" that does both**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "62688179-29a2-4c95-9f9b-ce249a1c83c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dspy.functional import TypedChainOfThought\n",
    "class BasicQABot(dspy.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.generate = TypedChainOfThought(BasicQA)\n",
    "\n",
    "    def forward(self,question):\n",
    "        prediction = self.generate(question = question)\n",
    "        return dspy.Prediction(answer = prediction.answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c1b08de9-27c9-4b5c-9cb3-5b0fc4435bbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Country(name='Germany', capital='Berlin', population=83783942)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_bot = BasicQABot()\n",
    "pred = qa_bot.forward(\"which of France's neighbor country has the most population?\")\n",
    "pred.answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0b80edb6-d935-42ce-b436-1a0c58c99bc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "Given the fields `question`, produce the fields `answer`.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Reasoning: Let's think step by step in order to ${produce the answer}. We ...\n",
      "Answer: ${answer}. Respond with a single JSON object. JSON Schema: {\"properties\": {\"name\": {\"title\": \"Name\", \"type\": \"string\"}, \"capital\": {\"title\": \"Capital\", \"type\": \"string\"}, \"population\": {\"title\": \"Population\", \"type\": \"integer\"}}, \"required\": [\"name\", \"capital\", \"population\"], \"title\": \"Country\", \"type\": \"object\"}\n",
      "\n",
      "---\n",
      "\n",
      "Question: which of France's neighbor country has the most population?\n",
      "Reasoning: Let's think step by step in order to\u001b[32m produce the answer. We first need to identify France's neighboring countries, which are Spain, Italy, Germany, Switzerland, Luxembourg, Belgium, and Monaco. Next, we need to determine the population of each of these countries and compare them to find the one with the highest population.\n",
      "\n",
      "Answer: {\"name\": \"Germany\", \"capital\": \"Berlin\", \"population\": 83783942}\u001b[0m\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lm.inspect_history(n=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3aae283-726c-46ac-9cc4-b768f66ecb4b",
   "metadata": {},
   "source": [
    "## Multi-Hop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c752c25-2d3b-43a8-9d5e-37ae092bb599",
   "metadata": {},
   "source": [
    "Search the examples in DSPy, we can find Multi-Hop examples like https://github.com/stanfordnlp/dspy/blob/fc664d5e339d2c16b3b537bdbb13d9707e6fd9c4/skycamp2023.ipynb#L306. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be3608b-1d72-427e-b95b-8d16b6f652d9",
   "metadata": {},
   "source": [
    "In above example, it has 3 steps:\n",
    "1. given a question, ask LLM to return a search query\n",
    "2. using a \"retriever\" from DSPy, run the search\n",
    "3. given the search results, ask LLM to return answer\n",
    "\n",
    "Since we want to focus on the \"prompt\" part, we will do #1 and #3, and just hard code the search results like below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7d9fc628-0822-4d4a-b953-5102d6e17d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class BasicQABot(dspy.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.generate_query = dspy.ChainOfThought(\"question -> search_query\")\n",
    "        self.generate_answer = dspy.ChainOfThought(\"context, question -> answer\")\n",
    "\n",
    "    def forward(self,question):\n",
    "        # generate a search query from the question, and use it to retrieve passages\n",
    "        search_query = self.generate_query(question=question).search_query\n",
    "        print(\"search:\", search_query)\n",
    "        # here we are supposely to do the search and pass the search results to context.\n",
    "        passages = \"\"\"\n",
    "            country, population\n",
    "            Germany, 10000000\n",
    "            Belgium, 10000000000\n",
    "            Spain, 100000\n",
    "        \"\"\"\n",
    "        print(\"search results\", passages)\n",
    "        # generate an answer from the passages and the question\n",
    "        return self.generate_answer(context=passages, question=question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1b2b1242-2c52-4b9a-bf7a-8927a5611109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search: France neighboring countries population statistics\n",
      "search results \n",
      "            country, population\n",
      "            Germany, 10000000\n",
      "            Belgium, 10000000000\n",
      "            Spain, 100000\n",
      "        \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Belgium, with a population of 10,000,000, is the neighbor country of France with the most population.'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_bot = BasicQABot()\n",
    "pred = qa_bot.forward(\"which of France's neighbor country has the most population?\")\n",
    "pred.answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a240880-857a-4213-9026-8ab02b7b67fb",
   "metadata": {},
   "source": [
    "In above exercise, we are using the magical signature \"context, question -> answer\". It works, but unfortunately we are not getting JSON output since we are not specifying the answer type as before\n",
    "```\n",
    "class BasicQA(dspy.Signature):\n",
    "    ...\n",
    "    answer: Country = dspy.OutputField()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43063885-4808-434b-bbf1-534b7490eb72",
   "metadata": {},
   "source": [
    "## So What is Signature Anyway?\n",
    "\n",
    "So far we have seen the magic string like \"question -> answer\", \"question -> search_query\", \"context, question -> answer\", they are referred as \"Signature\" in DSPy. \n",
    "\n",
    "self.generate_query = dspy.ChainOfThought(\"question -> search_query\")\n",
    "\n",
    "The \"dspy.ChainOfThought\" is a Predict, let's take a look at it - https://github.com/stanfordnlp/dspy/blob/fc664d5e339d2c16b3b537bdbb13d9707e6fd9c4/docs/api/modules/Predict.md\n",
    "\n",
    "```\n",
    "class Predict(Parameter):\n",
    "    def __init__(self, signature, **config):\n",
    "        self.stage = random.randbytes(8).hex()\n",
    "        self.signature = signature\n",
    "        self.config = config\n",
    "        self.reset()\n",
    "\n",
    "        if isinstance(signature, str):\n",
    "            inputs, outputs = signature.split(\"->\")\n",
    "            inputs, outputs = inputs.split(\",\"), outputs.split(\",\")\n",
    "            inputs, outputs = [field.strip() for field in inputs], [field.strip() for field in outputs]\n",
    "\n",
    "            assert all(len(field.split()) == 1 for field in (inputs + outputs))\n",
    "\n",
    "            inputs_ = ', '.join([f\"`{field}`\" for field in inputs])\n",
    "            outputs_ = ', '.join([f\"`{field}`\" for field in outputs])\n",
    "\n",
    "            instructions = f\"\"\"Given the fields {inputs_}, produce the fields {outputs_}.\"\"\"\n",
    "\n",
    "            inputs = {k: InputField() for k in inputs}\n",
    "            outputs = {k: OutputField() for k in outputs}\n",
    "\n",
    "            for k, v in inputs.items():\n",
    "                v.finalize(k, infer_prefix(k))\n",
    "            \n",
    "            for k, v in outputs.items():\n",
    "                v.finalize(k, infer_prefix(k))\n",
    "\n",
    "            self.signature = dsp.Template(instructions, **inputs, **outputs)\n",
    "```\n",
    "\n",
    "**So, the signature specifies the inputs and outputs. When it is string like 'context, question -> answer', DSPy will parse it through the '->' and ',' to decide the fields. Otherwise, it can be defined with code like the BasicQA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "28662dde-1ca9-4884-84ed-107b6b60b95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenerateSearchQuery(dspy.Signature):\n",
    "    question = dspy.InputField()\n",
    "    search_query: str = dspy.OutputField()\n",
    "    \n",
    "class GenerateAnswer(dspy.Signature):\n",
    "    context = dspy.InputField(desc=\"may contain relevant facts\")\n",
    "    question = dspy.InputField()\n",
    "    answer: Country = dspy.OutputField()\n",
    "\n",
    "class BasicQABot(dspy.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.generate_query = TypedChainOfThought(GenerateSearchQuery)\n",
    "        self.generate_answer = TypedChainOfThought(GenerateAnswer)\n",
    "\n",
    "    def forward(self,question):\n",
    "        # generate a search query from the question, and use it to retrieve passages\n",
    "        search_query = self.generate_query(question=question).search_query\n",
    "        print(\"search:\", search_query)\n",
    "        # here we are supposely to do the search and pass the search results to context.\n",
    "        passages = \"\"\"\n",
    "            country, population\n",
    "            Germany, 10000000\n",
    "            Belgium, 10000000000\n",
    "            Spain, 100000\n",
    "        \"\"\"\n",
    "        print(\"search results\", passages)\n",
    "        # generate an answer from the passages and the question\n",
    "        return self.generate_answer(context=passages, question=question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "eb01e64f-84b4-454d-8679-72f659e44345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search: France neighboring countries population statistics\n",
      "search results \n",
      "            country, population\n",
      "            Germany, 10000000\n",
      "            Belgium, 10000000000\n",
      "            Spain, 100000\n",
      "        \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Country(name='Belgium', capital='Brussels', population=10000000000)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_bot = BasicQABot()\n",
    "pred = qa_bot.forward(\"which of France's neighbor country has the most population?\")\n",
    "pred.answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4b41b4-8e25-433a-9b17-14c361073c28",
   "metadata": {},
   "source": [
    "**Now we have JSON results**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2b9961-1428-4c3a-a5af-cacf7fd3064d",
   "metadata": {},
   "source": [
    "## Thoughts\n",
    "\n",
    "1. **Loving DSPy for Prompt Help**: It's awesome that DSPy is tackling the dark arts of LLM prompting so I don't have to.\n",
    "2. **Exploring More Down the Road**: There's a bunch more to this whole topic. We only touched the very basic so far.\n",
    "3. **Another framework?**: Just like with other frameworks, there's a specific way to code to get the most out of it. I get why it's called the \"PyTorch of prompting\" and all, it has the vibe of the \"ORM-for-Prompt\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc97e16-bc6f-4668-9d50-da1b12d17813",
   "metadata": {},
   "source": [
    "I stepped upon this at https://github.com/stanfordnlp/dspy/issues/253, and I think it presents the architecture of DPSy very well.\n",
    "![diagram](./from_issue_253.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8c20c1-0c4f-4afa-a1c5-89d1ab361c93",
   "metadata": {},
   "source": [
    "**Next, we will explore the feedback loops - the optimizor, assertions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aad2945-1e4b-4b8f-8ff8-61c414aa70c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
